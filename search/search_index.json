{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Web Scraping - Casar\u00e3o Im\u00f3veis","text":"<p>Este projeto realiza web scraping no site Casar\u00e3o Im\u00f3veis, com o objetivo de coletar informa\u00e7\u00f5es de im\u00f3veis para aluguel em Pelotas/RS.</p> <p>A coleta \u00e9 feita utilizando o Selenium, com rolagem din\u00e2mica da p\u00e1gina e abertura individual de cada card de im\u00f3vel. Os dados s\u00e3o ent\u00e3o transformados e salvos no formato JSON.</p> <p>Observa\u00e7\u00e3o: o resultado n\u00e3o gera valor algum, projeto realizado para estudo devido \u00e0s dificuldades encontradas no site, e para a pratica das tecnologias utilizadas.</p>"},{"location":"#estrutura-da-documentacao","title":"Estrutura da Documenta\u00e7\u00e3o","text":"<ol> <li>Fontes de Dados</li> <li>Arquitetura do Projeto</li> <li>L\u00f3gica de Coleta</li> <li>Armazenamento de Dados</li> <li>Ambiente e Execu\u00e7\u00e3o</li> </ol>"},{"location":"1_data_sources/","title":"1. Fontes de Dados","text":"<p>O projeto extrai informa\u00e7\u00f5es do site da Casar\u00e3o Im\u00f3veis, focando nos im\u00f3veis dispon\u00edveis para aluguel em Pelotas/RS.</p>"},{"location":"1_data_sources/#site-alvo","title":"\ud83c\udf10 Site alvo","text":"<ul> <li>URL principal: https://casaraoimoveis.com.br/imoveis/alugueis/pelotas/todos-os-tipos/</li> </ul>"},{"location":"1_data_sources/#estrutura-da-pagina","title":"\ud83d\udd0d Estrutura da P\u00e1gina","text":"<p>A listagem de im\u00f3veis est\u00e1 em um container com ID <code>#imoveis</code>, onde cada card representa um im\u00f3vel.</p>"},{"location":"1_data_sources/#exemplos-de-elementos-capturados","title":"Exemplos de elementos capturados:","text":"<ul> <li> <p>Endere\u00e7o:   Extra\u00eddo do seletor <code>p.endereco</code> em cada p\u00e1gina individual do im\u00f3vel.</p> </li> <li> <p>Caracter\u00edsticas (aluguel, condom\u00ednio, IPTU, total etc):   Coletadas a partir de um container com v\u00e1rias <code>div.row</code>, onde cada linha tem:</p> </li> <li>Nome (ex: \"Aluguel\", \"IPTU\")</li> <li> <p>Valor correspondente (ex: \"R$ 4.100,00\")</p> </li> <li> <p>Tipo de im\u00f3vel (casa, apartamento, loja, etc...):</p> </li> <li>Coletado a partir da URL do card.</li> </ul>"},{"location":"1_data_sources/#estrategia-de-navegacao","title":"\ud83e\udded Estrat\u00e9gia de navega\u00e7\u00e3o","text":"<ol> <li>A p\u00e1gina principal exige scroll infinito para carregar todos os im\u00f3veis.</li> <li>Cada im\u00f3vel possui um link para sua p\u00e1gina individual.</li> <li>As informa\u00e7\u00f5es completas s\u00e3o acessadas apenas ao abrir cada p\u00e1gina de im\u00f3vel.</li> </ol>"},{"location":"1_data_sources/#consideracoes","title":"\ud83e\uddea Considera\u00e7\u00f5es","text":"<ul> <li>Alguns cards podem ser propagandas e n\u00e3o possuem link (<code>&lt;a&gt;</code>), sendo ignorados.</li> <li>Alguns campos, como \"Condom\u00ednio\" ou \"IPTU\", podem conter <code>\"\"---\"</code> quando ausentes.</li> <li>H\u00e1 alguns endere\u00e7os que o logradouro vem com abreviados como \"R\"(rua), \"Pr\u00e7\"(pra\u00e7a), \"Av\"(avenida). </li> <li>No momento do Extract, a chave <code>\"TOTAL\"</code> pode aparecer duplicada com varia\u00e7\u00f5es como:</li> <li><code>\"TOTAL:\\nR$ 4.100,00\"</code></li> <li><code>\"TOTAL:\"</code></li> </ul> <p>Essas inconsist\u00eancias s\u00e3o tratadas na etapa de transforma\u00e7\u00e3o de dados.</p>"},{"location":"2_architecture/","title":"2. Arquitetura do Projeto","text":"<p>Este projeto \u00e9 dividido em duas fases principais: extra\u00e7\u00e3o e transforma\u00e7\u00e3o de dados.</p>"},{"location":"2_architecture/#estrutura-de-diretorios","title":"\ud83d\uddc2\ufe0f Estrutura de Diret\u00f3rios","text":"<p>webscraping_selenium             \u251c\u2500 data                           \u2502  \u251c\u2500 resultados_clean.json      \u2502  \u2514\u2500 resultados_raw.json        \u251c\u2500 docs                          \u2502  \u251c\u2500 assets                     \u2502  \u251c\u2500 0_index.md                 \u2502  \u251c\u2500 1_data_sources.md          \u2502  \u251c\u2500 2_architecture.md          \u2502  \u251c\u2500 3_scraping_logic.md        \u2502  \u251c\u2500 4_data_storage.md          \u2502  \u2514\u2500 5_setup.md                 \u251c\u2500 sql                           \u2502  \u2514\u2500 create_table.sql           \u251c\u2500 src                                 \u2502  \u251c\u2500 extract_data.py            \u2502  \u251c\u2500 load_data.py               \u2502  \u2514\u2500 transform_data.py                                    \u251c\u2500 main.py                       \u251c\u2500 poetry.lock                   \u251c\u2500 pyproject.toml                \u2514\u2500 README.md                      </p>"},{"location":"2_architecture/#componentes-do-pipeline","title":"\u2699\ufe0f Componentes do Pipeline","text":""},{"location":"2_architecture/#1-extract_datapy","title":"\ud83d\udfe6 1. <code>extract_data.py</code>","text":"<p>Respons\u00e1vel por: - Utilizar o Selenium para navegar pela p\u00e1gina principal e abrir os links dos im\u00f3veis. - Extrair o endere\u00e7o e as caracter\u00edsticas de cada im\u00f3vel. - Salvar o resultado bruto em <code>data/resultados_raw.json</code>.</p>"},{"location":"2_architecture/#2-transform_datapy","title":"\ud83d\udfe8 2. <code>transform_data.py</code>","text":"<p>Respons\u00e1vel por: - Normalizar os endere\u00e7os (ex: \"R.\" \u2192 \"Rua\", \"Av.\" \u2192 \"Avenida\"). - Eliminar entradas duplicadas ou inconsistentes da chave <code>\"TOTAL\"</code>. - Salvar o resultado limpo em <code>data/resultados_clean.json</code>.</p>"},{"location":"2_architecture/#3-load_datapy","title":"\ud83d\udfe9 3. <code>load_data.py</code>","text":"<p>Respons\u00e1vel por: - Ler o arquivo <code>resultados_clean.json</code>. - Conectar-se a um banco de dados PostgreSQL. - Inserir os registros na tabela apropriada.</p>"},{"location":"2_architecture/#pipeline-de-execucao","title":"\u2699\ufe0f Pipeline de Execu\u00e7\u00e3o","text":"<pre><code>flowchart TD\n    Start([\ud83d\ude80 In\u00edcio da Pipeline])\n\n    Extract[\ud83d\udce5 extract_data.py \u27a1\ufe0f Coleta dados com Selenium]\n    Transform[\ud83e\uddf9 transform_data.py\u27a1\ufe0f Gera resultados_clean.json]\n    Load[\ud83d\uddc4\ufe0f load_data.py\u27a1\ufe0f Insere dados no PostgreSQL]\n\n    DB[(\ud83d\udfe2 PostgreSQLTabela de im\u00f3veis)]\n\n    Start --&gt; Extract --&gt; Transform --&gt; Load --&gt; DB\n</code></pre>"},{"location":"3_scraping_logic/","title":"3. L\u00f3gica de Scraping","text":"<p>A coleta dos dados \u00e9 feita com o Selenium a partir da p\u00e1gina principal da listagem de im\u00f3veis. O processo envolve rolagem din\u00e2mica, identifica\u00e7\u00e3o de elementos, e extra\u00e7\u00e3o individualizada por im\u00f3vel.</p>"},{"location":"3_scraping_logic/#estrategia-geral","title":"\ud83e\udde0 Estrat\u00e9gia Geral","text":"<ul> <li>Carregar a p\u00e1gina com todos os im\u00f3veis dispon\u00edveis.</li> <li>Fazer scroll at\u00e9 que nenhum novo im\u00f3vel seja carregado.</li> <li>Para cada im\u00f3vel:</li> <li>Verificar se \u00e9 um card v\u00e1lido (com link).</li> <li>Abrir a p\u00e1gina do im\u00f3vel em uma nova aba.</li> <li>Extrair endere\u00e7o e caracter\u00edsticas.</li> <li>Fechar a aba e voltar \u00e0 listagem.</li> </ul>"},{"location":"3_scraping_logic/#detalhamento-das-funcoes","title":"\ud83d\udd0d Detalhamento das Fun\u00e7\u00f5es","text":""},{"location":"3_scraping_logic/#carregar_todos_os_cardsdriver","title":"<code>carregar_todos_os_cards(driver)</code>","text":"<ul> <li>Fun\u00e7\u00e3o: Carrega todos os cards de im\u00f3veis em uma p\u00e1gina com scroll incremental.  </li> <li>M\u00e9todos utilizados:  </li> <li>Faz scroll incremental via JavaScript (<code>window.scrollBy</code>).  </li> <li>Aguarda dinamicamente o carregamento de novos cards.  </li> <li>Interrompe ap\u00f3s N tentativas sem novos cards (evita loops infinitos).  </li> </ul>"},{"location":"3_scraping_logic/#extrair_enderecodriver","title":"<code>extrair_endereco(driver)</code>","text":"<ul> <li>Fun\u00e7\u00e3o: Extrai detalhes do endere\u00e7o e caracter\u00edsticas do im\u00f3vel.  </li> <li>Fluxo:  </li> <li>Acessa a p\u00e1gina do im\u00f3vel (abre nova aba).  </li> <li>Usa <code>WebDriverWait</code> para garantir que o elemento do endere\u00e7o esteja carregado.  </li> <li>Extrai dados estruturados com base em seletores:  <ul> <li>Padr\u00e3o HTML: <code>div.row &gt; div.col</code> (valores).  </li> </ul> </li> </ul>"},{"location":"3_scraping_logic/#padroes-e-boas-praticas","title":"\ud83d\udccc Padr\u00f5es e Boas Pr\u00e1ticas","text":""},{"location":"3_scraping_logic/#1-espera-explicita","title":"1. Espera Expl\u00edcita","text":"<ul> <li>Utiliza <code>WebDriverWait</code> + <code>expected_conditions</code> para evitar falhas por:  </li> <li>Carregamento lento.  </li> <li>Elementos din\u00e2micos.  </li> </ul>"},{"location":"3_scraping_logic/#2-tratamento-de-excecoes","title":"2. Tratamento de Exce\u00e7\u00f5es","text":"<ul> <li>Ignora elementos irrelevantes (ex.: propagandas) sem interromper o fluxo.  </li> <li>Exemplo:   ```python   try:       WebDriverWait(driver, 10).until(EC.presence_of_element_located(...))   except TimeoutException:       print(\"Elemento n\u00e3o encontrado - pulando...\")</li> </ul>"},{"location":"3_scraping_logic/#fluxo-logico-completo","title":"\ud83d\udd04 Fluxo L\u00f3gico Completo","text":"<pre><code>flowchart TD\n    A[\ud83c\udf10 Acessar p\u00e1gina inicial] --&gt; B[\u2b07\ufe0f Fazer scroll para carregar im\u00f3veis]\n    B --&gt; C{\u2753 Novos im\u00f3veis carregados?}\n    C -- Sim --&gt; B\n    C -- N\u00e3o --&gt; D[\ud83d\udd01 Iterar sobre cada card]\n\n    D --&gt; E{\u2753 Card tem link v\u00e1lido?}\n    E -- N\u00e3o --&gt; D\n    E -- Sim --&gt; F[\ud83c\udd95 Abrir nova aba com im\u00f3vel]\n    F --&gt; G[\u23f3 Esperar carregamento]\n    G --&gt; H[\ud83c\udfe0 Extrair endere\u00e7o\ud83e\uddfe Extrair caracter\u00edsticas]\n    H --&gt; I[\u274c Fechar aba]\n    I --&gt; D\n</code></pre>"},{"location":"4_data_storage/","title":"4. Armazenamento de Dados","text":"<p>Os dados coletados e transformados passam por duas formas de armazenamento:</p> <ol> <li>Arquivos locais (<code>JSON</code>) para debug e hist\u00f3rico.</li> <li>Banco de dados PostgreSQL para an\u00e1lise estruturada e integra\u00e7\u00e3o com outras ferramentas.</li> </ol>"},{"location":"4_data_storage/#armazenamento-em-arquivos","title":"\ud83d\udcc1 Armazenamento em Arquivos","text":"<p>Ap\u00f3s cada etapa da pipeline, os dados s\u00e3o salvos para inspe\u00e7\u00e3o ou reprocessamento:</p> <pre><code>flowchart TD\n    A[\ud83d\udce5 extract_data.py] --&gt; B[data/resultados_raw.json]\n    B --&gt; C[\ud83e\uddf9 transform_data.py]\n    C --&gt; D[data/resultados_clean.json]\n</code></pre>"},{"location":"4_data_storage/#armazenamento-em-banco-de-dados-postgresql","title":"\ud83d\uddc4\ufe0f Armazenamento em Banco de Dados (PostgreSQL)","text":"<p>O script load_data.py \u00e9 respons\u00e1vel por ler o resultados_clean.json e inserir os dados no banco PostgreSQL.</p> <pre><code>flowchart TD\n    JSON[data/resultados_clean.json] --&gt; LOAD[load_data.py]\n    LOAD --&gt; DB[(\ud83d\udfe2 PostgreSQLTabela de im\u00f3veis)]\n</code></pre>"},{"location":"4_data_storage/#modelo-de-tabela","title":"\ud83e\uddf1 Modelo de Tabela","text":"<p>A estrutura no banco \u00e9 planejada para refletir as informa\u00e7\u00f5es dos im\u00f3veis. Um modelo t\u00edpico da tabela pode ser:</p> <p>CREATE TABLE imoveis (     id SERIAL PRIMARY KEY,     url TEXT,     endereco TEXT,     aluguel TEXT,     condominio TEXT,     iptu TEXT,     total TEXT );</p>"},{"location":"4_data_storage/#resultado","title":"\u2705 Resultado","text":"<pre><code>flowchart TD\n    Inicio([\ud83d\ude80 Dados transformados])\n    Inicio --&gt; Arq[\ud83d\udcc1 Salvo em JSON]\n    Arq --&gt; Banco[\ud83d\uddc3\ufe0f Inserido no PostgreSQL]\n    Banco --&gt; Analise[\ud83d\udcc8 Pronto para an\u00e1lise ou dashboards]\n</code></pre>"},{"location":"5_setup/","title":"5. Setup do Projeto","text":"<p>Este guia mostra como configurar o ambiente com Poetry, instalar as depend\u00eancias e executar a pipeline completa \u2014 da extra\u00e7\u00e3o dos dados ao carregamento no PostgreSQL.</p>"},{"location":"5_setup/#requisitos","title":"\ud83e\uddf1 Requisitos","text":"<ul> <li>Python 3.9+</li> <li>Poetry</li> <li>Google Chrome</li> <li>ChromeDriver</li> <li>PostgreSQL</li> </ul>"},{"location":"5_setup/#instalacao-com-poetry","title":"\u2699\ufe0f Instala\u00e7\u00e3o com Poetry","text":"<pre><code># 1. Clone o reposit\u00f3rio\ngit clone https://github.com/lenontorma/webscraping_selenium.git\ncd webscraping_selenium\n\n# 2. Instale as depend\u00eancias com Poetry que est\u00e3o no pyproject.toml\npoetry install\n\n# 3. Ative o ambiente virtual do Poetry\npoetry shell (Deve ser instalada a extens\u00e3o \"poetry self add poetry-plugin-shell\")\n</code></pre>"},{"location":"5_setup/#banco-postgresql","title":"\ud83d\udee0\ufe0f Banco PostgreSQL","text":"<pre><code>CREATE DATABASE webscraping;\n\n\\c webscraping\n\nCREATE TABLE imoveis (\n    id SERIAL PRIMARY KEY,\n    url TEXT,\n    endereco TEXT,\n    aluguel TEXT,\n    condominio TEXT,\n    iptu TEXT,\n    total TEXT\n);\n\nE n\u00e3o se esque\u00e7a, ajuste a conex\u00e3o no load_data.py com suas credenciais PostgreSQL.\n</code></pre>"},{"location":"5_setup/#rodar-a-documentacao-local","title":"\ud83d\udcda Rodar a Documenta\u00e7\u00e3o Local","text":"<pre><code>poetry add mkdocs --group docs\npoetry run mkdocs serve\n</code></pre> <p>Acesse via: http://localhost:8000</p>"}]}