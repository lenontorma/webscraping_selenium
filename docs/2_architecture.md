# 2. Arquitetura do Projeto

Este projeto Ã© dividido em duas fases principais: **extraÃ§Ã£o** e **transformaÃ§Ã£o** de dados.

## ðŸ—‚ï¸ Estrutura de DiretÃ³rios

webscraping_selenium              
â”œâ”€ data                            
â”‚  â”œâ”€ resultados_clean.json       
â”‚  â””â”€ resultados_raw.json         
â”œâ”€ docs                           
â”‚  â”œâ”€ assets                      
â”‚  â”œâ”€ 0_index.md                  
â”‚  â”œâ”€ 1_data_sources.md           
â”‚  â”œâ”€ 2_architecture.md           
â”‚  â”œâ”€ 3_scraping_logic.md         
â”‚  â”œâ”€ 4_data_storage.md           
â”‚  â””â”€ 5_setup.md                  
â”œâ”€ sql                            
â”‚  â””â”€ create_table.sql            
â”œâ”€ src                                  
â”‚  â”œâ”€ extract_data.py             
â”‚  â”œâ”€ load_data.py                
â”‚  â””â”€ transform_data.py                                     
â”œâ”€ main.py                        
â”œâ”€ poetry.lock                    
â”œâ”€ pyproject.toml                 
â””â”€ README.md                      


## âš™ï¸ Componentes do Pipeline

### ðŸŸ¦ 1. `extract_data.py`
ResponsÃ¡vel por:
- Utilizar o Selenium para navegar pela pÃ¡gina principal e abrir os links dos imÃ³veis.
- Extrair o endereÃ§o e as caracterÃ­sticas de cada imÃ³vel.
- Salvar o resultado bruto em `data/resultados_raw.json`.

### ðŸŸ¨ 2. `transform_data.py`
ResponsÃ¡vel por:
- Normalizar os endereÃ§os (ex: "R." â†’ "Rua", "Av." â†’ "Avenida").
- Eliminar entradas duplicadas ou inconsistentes da chave `"TOTAL"`.
- Salvar o resultado limpo em `data/resultados_clean.json`.

### ðŸŸ© 3. `load_data.py`
ResponsÃ¡vel por:
- Ler o arquivo `resultados_clean.json`.
- Conectar-se a um banco de dados PostgreSQL.
- Inserir os registros na tabela apropriada.

## ðŸ” Fluxo do Pipeline (ETL)

```mermaid
graph LR
    A[extract_data.py] --> B[data/resultados_raw.json]
    B --> C[transform_data.py]
    C --> D[data/resultados_clean.json]
    D --> E[load_data.py]
    E --> F[(PostgreSQL)]